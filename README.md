## Implementa√ß√£o do M√©todo de M√≠nimos Quadrados e M√©tricas para Modelo de Regress√£o Linear com Python
O m√©todo dos m√≠nimos quadrados √© o mesmo que reta de regress√£o linear s√≠mples ou reta de ajuste.
Interessante estudar esse modelo porque temos aplica√ß√µes em Machine Learning ü¶æ.

![Amostras](/imgs/output.png)


## M√©todo dos M√≠nimos Quadrados ‚úîÔ∏è

O m√©todo dos m√≠nimos quadrados √© utilizado para ajustar um modelo de regress√£o linear aos dados observados, minimizando a soma dos quadrados dos res√≠duos (as diferen√ßas entre os valores observados e os valores preditos).
Para uma regress√£o linear simples com uma vari√°vel independente, a f√≥rmula dos coeficientes √©:

**Coeficiente Angular $A$**

$$ 
A = \frac { \sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y}) } { \sum_{i=1}^{n} (x_i - \bar{x})^2 }
$$

**Coeficiente Linear $B$**

$$ B = \bar{y} - A \bar{x} $$

onde:
- **$x_i$**  s√£o os valores da vari√°vel independente,
- **$y_i$** s√£o os valores observados da vari√°vel dependente,
- **$\bar{x}$** √© a m√©dia dos valores da vari√°vel independente,
- **$\bar{y}$** √© a m√©dia dos valores da vari√°vel dependente,
- **$n$** √© o n√∫mero de observa√ß√µes.

### Equa√ß√£o da Regress√£o Linear
A equa√ß√£o da reta de regress√£o linear ajustada √© dada por:

$$ \hat{y} = B + A x $$

onde:
- **$\hat{y}$** √© o valor predito da vari√°vel dependente,
- **$A$** √© o coeficiente angular,
- **$B$** √© o coeficiente linear,
- **$x$** √© o valor da vari√°vel independente.

Usaremos essas f√≥rmulas para calcular os coeficientes que melhor se ajustam aos dados, minimizando a soma dos quadrados das diferen√ßas entre os valores observados e os valores preditos ü§ì.

## M√©tricas Performance ‚úîÔ∏è

### Raiz do Erro Quadr√°tico M√©dio (RMSE)

A Raiz do Erro Quadr√°tico M√©dio (RMSE) √© uma m√©trica que mede a m√©dia dos erros ao quadrado entre os valores observados e os valores preditos (MSE). Ela tem a mesma unidade dos valores observados, o que facilita a interpreta√ß√£o.

$$\text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}$$

onde:
- **$y_i$** s√£o os valores observados,
- **$\hat{y}_i$** s√£o os valores preditos pelo modelo, para cada **$y_i$**,
- **$n$** √© o n√∫mero de observa√ß√µes.

### Coeficiente de Determina√ß√£o R¬≤

O Coeficiente de Determina√ß√£o R¬≤ √© uma m√©trica que mede a propor√ß√£o da variabilidade dos dados que √© explicada pelo modelo de regress√£o. Ele varia entre 0 e 1, onde 1 indica um ajuste perfeito e 0 indica que o modelo n√£o explica a variabilidade dos dados.

$$
R^2 = 1 - \frac {\sum_{i=1}^{n} (y_i - \hat{y}_i)^2} {\sum_{i=1}^{n} (y_i - \bar{y})^2}
$$

onde:
- **$y_i$** s√£o os valores observados,
- **$\hat{y}_i$** s√£o os valores preditos pelo modelo,
- **$\bar{y}$** √© a m√©dia dos valores observados,
- **$n$** √© o n√∫mero de observa√ß√µes.


